name: CD Pipeline for Azure Databricks

on:
  push:
    branches:
      - main

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.x'

    - name: Install Databricks CLI
      run: pip install databricks-cli

    - name: Import Notebook to Workspace
      run: |
        # Use a unique notebook path to avoid folder conflict
        databricks workspace import sample_sales_notebook.py /Users/admin@mngenvmcap835596.onmicrosoft.com/CI-CD/sample_sales_notebook -l python --overwrite
      env:
        DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
        DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}

    - name: Run Databricks Job
      run: |
        # Create the job from config
        databricks jobs create --json-file job-config.json

        # Extract job ID and trigger it
        JOB_ID=$(databricks jobs list | grep -m 1 'CD pipeline' | awk '{print $1}')
        databricks jobs run-now --job-id $JOB_ID
      env:
        DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
        DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
